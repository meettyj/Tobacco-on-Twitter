{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/eddie/Desktop/Prof. Rumi Chunara/alcohol')\n",
    "import pickle\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas\n",
    "import numpy as np\n",
    "import sys\n",
    "from evaluation.metric import computeAccuracy, computeF1Score, computeAUC\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import uniform\n",
    "# %reload_ext pipelines.alcohol.AlcoholPipeline\n",
    "from pipelines.alcohol import AlcoholPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_alc_initial = pickle.load(open('./alcohol classifiers/clf_alc_UPDATED.p', 'rb'))\n",
    "# clf_fpa    = pickle.load(open('./alcohol classifiers/clf_fpa_UPDATED.p', 'rb'))\n",
    "# clf_fpl_dl = pickle.load(open('./alcohol classifiers/clf_fpl_double_labeled', 'rb'))\n",
    "df = pandas.read_csv(\"./data/alcohol_training_instances.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=T...one,\n",
       "          solver='liblinear', tol=0.000655077907893521, verbose=0,\n",
       "          warm_start=None))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_alc_initial\n",
    "# with open('structure.txt', 'w') as f:\n",
    "#     tmp = ''.join(str(e) for e in clf_alc_initial.steps)\n",
    "#     f.write(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the alcohol data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "15651\n"
     ]
    }
   ],
   "source": [
    "alc_labels = []\n",
    "# extracting pre-labeled classification\n",
    "for i in range(0,len(df.labels)):\n",
    "    alc_labels.append(df.labels[i][12])\n",
    "alc_labels = list(map(int, alc_labels))\n",
    "print(alc_labels[:10])\n",
    "print(len(alc_labels))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, alc_labels, test_size=0.1, random_state=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check the initial model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  1566\n",
      "pretrained alcohol classifer:  261 different item in whole dataset\n",
      "accuracy: 83.333333%\n",
      "F1 Score:  0.8718703976435936\n",
      "alcohol LR AUC:  0.8722371835589783\n"
     ]
    }
   ],
   "source": [
    "clf_alc_initial.fit(X_train, y_train)\n",
    "# predict in testing set.\n",
    "y_alc_initial = clf_alc_initial.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_alc_initial, y_test)\n",
    "f1 = computeF1Score(y_test, y_alc_initial)\n",
    "print('F1 Score: ', f1)\n",
    "auc_score_initial = computeAUC(clf_alc_initial, X_test, y_test, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('alcohol LR AUC: ', auc_score_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=71233, min_df=1,\n",
       "     ...      token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None))]))],\n",
       "         transformer_weights=None)),\n",
       " ('scaler', Normalizer(copy=True, norm='l2')),\n",
       " ('clf',\n",
       "  LogisticRegression(C=177.08103265690417, class_weight=None, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=None, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.000655077907893521, verbose=0,\n",
       "            warm_start=None))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_alc_initial.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make our own LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "      ...      token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None))]))],\n",
       "         transformer_weights=None)),\n",
       " ('scaler', Normalizer(copy=True, norm='l2')),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR\n",
    "clf_alc_LR = AlcoholPipeline(global_features=[\"text\"]).pipeline(LogisticRegression())\n",
    "clf_alc_LR.steps\n",
    "# SVM\n",
    "# clf_alc_SVM = AlcoholPipeline(global_features=[\"text\"]).pipeline(LinearSVC())\n",
    "# clf_alc_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=T...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_alc_LR.fit(X_train, y_train)\n",
    "# pred_alc= clf_alc_LR.predict(df)\n",
    "# print(pred_alc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  1566\n",
      "pretrained alcohol classifer:  473 different item in whole dataset\n",
      "accuracy: 69.795658%\n",
      "F1 Score:  0.7920879120879121\n",
      "alcohol LR AUC:  0.7355430615269662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# predict in testing set.\n",
    "y_alc_LR = clf_alc_LR.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_alc_LR, y_test)\n",
    "f1_score_LR = computeF1Score(y_test, y_alc_LR)\n",
    "print('F1 Score: ', f1_score_LR)\n",
    "auc_score_LR = computeAUC(clf_alc_LR, X_test, y_test, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('alcohol LR AUC: ', auc_score_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test in training set to figure out why the test accuracy is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  14085\n",
      "pretrained alcohol classifer:  3981 different item in whole dataset\n",
      "accuracy: 71.735889%\n",
      "F1 Score:  0.8098944654027984\n",
      "alcohol LR AUC:  0.7389407159664841\n"
     ]
    }
   ],
   "source": [
    "# test in training set to figure out why the test accuracy is low\n",
    "y_train_alc_LR = clf_alc_LR.predict(X_train)\n",
    "computeAccuracy(y_train_alc_LR, y_train)\n",
    "f1_score_LR_train = computeF1Score(y_train, y_train_alc_LR)\n",
    "print('F1 Score: ', f1_score_LR_train)\n",
    "auc_score_LR_train = computeAUC(clf_alc_LR, X_train, y_train, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('alcohol LR AUC: ', auc_score_LR_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the performance in training set is also not good. So there must be sth wrong within the model structure parameters, since the model structure are same. Please see compareStructure.ipynb for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Update structure parameters in LR model. To make sure they become same with the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('getter',\n",
       "                                                                  ItemGetter(key='text')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(analyzer='char',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.int64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_features=71233,\n",
       "                                                                                  min_df=1,\n",
       "                                                                                  ngram_r...\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('scaler', Normalizer(copy=True, norm='l2')),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_alc_LR_updateParams = AlcoholPipeline(global_features=[\"text\"]).pipeline(LogisticRegression())\n",
    "params_LR = {'features__text__tfidf__dtype':np.int64, 'features__text__tfidf__max_features':71233, 'features__text__tfidf__ngram_range':(2,5) \n",
    "            }\n",
    "# to see all parameters in model\n",
    "# clf_alc_LR_updateParams.get_params().keys()\n",
    "clf_alc_LR_updateParams.set_params(**params_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', FeatureUnion(n_jobs=None,\n",
       "               transformer_list=[('text',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('getter',\n",
       "                                                   ItemGetter(key='text')),\n",
       "                                                  ('tfidf',\n",
       "                                                   TfidfVectorizer(analyzer='char',\n",
       "                                                                   binary=False,\n",
       "                                                                   decode_error='strict',\n",
       "                                                                   dtype=<class 'numpy.int64'>,\n",
       "                                                                   encoding='utf-8',\n",
       "                                                                   input='content',\n",
       "                                                                   lowercase=True,\n",
       "                                                                   max_df=1.0,\n",
       "                                                                   max_features=71233,\n",
       "                                                                   min_df=1,\n",
       "                                                                   ngram_range=(2,\n",
       "                                                                                5),\n",
       "                                                                   norm='l2',\n",
       "                                                                   preprocessor=None,\n",
       "                                                                   smooth_idf=True,\n",
       "                                                                   stop_words=None,\n",
       "                                                                   strip_accents=None,\n",
       "                                                                   sublinear_tf=False,\n",
       "                                                                   token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                                   tokenizer=None,\n",
       "                                                                   use_idf=True,\n",
       "                                                                   vocabulary=None))],\n",
       "                                           verbose=False))],\n",
       "               transformer_weights=None, verbose=False)),\n",
       " ('scaler', Normalizer(copy=True, norm='l2')),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_alc_LR_updateParams.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the LR model with updated parameters, and predict in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  1566\n",
      "pretrained alcohol classifer:  227 different item in whole dataset\n",
      "accuracy: 85.504470%\n",
      "F1 Score:  0.8927727916863486\n",
      "alcohol LR AUC:  0.8934052877388784\n"
     ]
    }
   ],
   "source": [
    "clf_alc_LR_updateParams.fit(X_train, y_train)\n",
    "# predict in testing set.\n",
    "y_alc_LR_updateParams = clf_alc_LR_updateParams.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_alc_LR_updateParams, y_test)\n",
    "f1_score_LR_updateParams = computeF1Score(y_test, y_alc_LR_updateParams)\n",
    "print('F1 Score: ', f1_score_LR_updateParams)\n",
    "auc_score_LR_updateParams = computeAUC(clf_alc_LR_updateParams, X_test, y_test, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('alcohol LR AUC: ', auc_score_LR_updateParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model we build with updated parameters achieve even better results than the initial model, compared to initial model with 0.87 in F1 score and 0.87 in AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
