{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('C:/Users/eddie/Desktop/Prof. Rumi Chunara/alcohol')\n",
    "os.chdir('/home/centos/Alcohol-on-Twitter')\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "import json\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from evaluation.metric import computeAccuracy, computeF1Score, computeAUC\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import uniform\n",
    "# %reload_ext pipelines.alcohol.AlcoholPipeline\n",
    "from pipelines.alcohol import AlcoholPipeline\n",
    "from pipelines.ecig import ECigPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test ----------\n",
    "# # df_test = pd.read_csv(\"./data/alcohol_training_instances.csv\")\n",
    "# df_test = pd.read_csv(\"/mnt/volume/result/alcohol_training_instances.csv\")\n",
    "# df_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_train:  801\n",
      "length of X_test:  201\n",
      "length of y_train:  801\n",
      "length of y_test:  201\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "# filePath = \"C:/Users/eddie/Desktop/Prof. Rumi Chunara/alcohol/data/labeled_figure_eight_csv_1000.csv\"\n",
    "filePath = \"/mnt/volume/labeled_data/labeled_figure_eight_csv_1000.csv\"\n",
    "df = pd.read_csv(filePath)\n",
    "df.is_this_posting_relevant_to_ecigarette[:3]\n",
    "\n",
    "# Deal with ecig_labels.\n",
    "ecig_labels = []\n",
    "# extracting pre-labeled classification\n",
    "for i in range(0,len(df.is_this_posting_relevant_to_ecigarette)):\n",
    "#     print(df.is_this_posting_relevant_to_ecigarette[i])\n",
    "    if df.is_this_posting_relevant_to_ecigarette[i] == 'ECIG':\n",
    "        ecig_labels.append(1)\n",
    "    elif df.is_this_posting_relevant_to_ecigarette[i] == 'NOT-ECIG':\n",
    "        ecig_labels.append(0)\n",
    "    else:\n",
    "        print('Should not go to here')\n",
    "# ecig_labels\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.realdonaldtrump_foxandfriends_smoke_blowing_up_your_orange_ass, ecig_labels, test_size=0.2, random_state=26)\n",
    "print('length of X_train: ', len(X_train))\n",
    "print('length of X_test: ', len(X_test))\n",
    "print('length of y_train: ', len(y_train))\n",
    "print('length of y_test: ', len(y_test))\n",
    "# X_train\n",
    "# y_train\n",
    "\n",
    "\n",
    "# # test ----------\n",
    "# df_test = pd.read_csv(\"./data/alcohol_training_instances.csv\")\n",
    "# df_test\n",
    "# df_test.labels[1]\n",
    "\n",
    "# alc_labels = []\n",
    "# # extracting pre-labeled classification\n",
    "# for i in range(0,len(df_test.labels)):\n",
    "#     alc_labels.append(df_test.labels[i][12])\n",
    "# alc_labels = list(map(int, alc_labels))\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_test, alc_labels, test_size=0.1, random_state=26)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ecig_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                  input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                  min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                  smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                  sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=None, use_idf=True, vocabulary=None)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR\n",
    "clf_ecig_LR = ECigPipeline().pipeline(LogisticRegression())\n",
    "clf_ecig_LR.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data into model to see the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/yijun/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ecig_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  201\n",
      "62 different item in whole dataset\n",
      "accuracy: 69.154229%\n",
      "F1 Score:  0.75\n",
      "alcohol LR AUC:  0.8499701729966197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46, 48],\n",
       "       [14, 93]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict in testing set.\n",
    "y_ecig_LR = clf_ecig_LR.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_ecig_LR, y_test)\n",
    "f1_score_LR = computeF1Score(y_test, y_ecig_LR)\n",
    "print('F1 Score: ', f1_score_LR)\n",
    "auc_score_LR = computeAUC(clf_ecig_LR, X_test, y_test, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('alcohol LR AUC: ', auc_score_LR)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_ecig_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results is fine. Now we will use this classifier on our San Francisco data to see how many of them are e-cig related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_filePath = '/mnt/volume/result/juliana_allSF_2018_01.json'\n",
    "df_SF_01 = pd.read_json(SF_filePath, lines=True, encoding='utf-8') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_SF_01[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Still totally love my boyfriend even if he can...\n",
       "1      @daniellenatoli1 @ me in a pic &amp; then maybe\n",
       "2    @imillhiser @IPM_GS @benwikler @RVAwonk @AdamP...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SF_01.text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_SF_01.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of San Francisco data:  278884\n",
      "How many of them the classifier said is positive (e-cig relevant)?\n"
     ]
    }
   ],
   "source": [
    "print('length of San Francisco data: ', len(df_SF_01))\n",
    "y_SF_LR = clf_ecig_LR.predict(df_SF_01.text)\n",
    "print('How many of them the classifier said is positive (e-cig relevant)?' % (sum(y_SF_LR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_SF_LR[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still totally love my boyfriend even if he can't ride a bike. We'll take the bus... https://t.co/c1S1OTqPfA\n",
      "------------\n",
      "@daniellenatoli1 @ me in a pic &amp; then maybe\n",
      "------------\n",
      "@imillhiser @IPM_GS @benwikler @RVAwonk @AdamParkhomenko @SarahLerner @brianbeutler @cristianafarias @jdawsey1‚Ä¶ https://t.co/Bf2nsE2POu\n",
      "------------\n",
      "@lilnatttt make your mind up, i need you to make your mind up\n",
      "------------\n",
      "@NatGeo .@NatGeo's book \"Those Inventive Americans\" emphasizes how original some human beings are and how their cre‚Ä¶ https://t.co/Ojyp84kFGU\n",
      "------------\n",
      "te amo te amo te amo https://t.co/anZ0k4S8xy\n",
      "------------\n",
      "@her_na_lnr –ú–µ–Ω—è —É–∂–µ –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∏–≤–ª—è–µ—Ç. –õ—É—á—à–µ –±—ã –ª–µ–≥–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ LSD.\n",
      "------------\n",
      "Most copped on Restocks last week?\n",
      "------------\n",
      "@matthewherper @daviesbj @jgreid @adamfeuerstein @Dr__Guess @YoniFreedhoff And that says a lot\n",
      "------------\n",
      "Jeremy Lamb shooting 2/3 from 3pt range. 8 points showing some good spot up shooting.\n",
      "------------\n",
      "TEST_LAT/LON: 7f521b31-f8d8-4c2e-85d2-ddb82626a1b8\n",
      "------------\n",
      "How much would y‚Äôall pay for someone to cook you breakfast, lunch and dinner  for a week?\n",
      "------------\n",
      "‚ÄúThere‚Äôs a Kremlin on the wing!‚Äù https://t.co/1ilynBLtIA\n",
      "------------\n",
      "TEST_LAT/LON: 83a9d6f8-3797-42ed-8679-ab75667ba50a\n",
      "------------\n",
      "YooooüòÇüòÇüòÇ so many people triggered https://t.co/xVOsg46B1I\n",
      "------------\n",
      "People go to Cochella to say they went to Cochella. Cochella sucks\n",
      "------------\n",
      "I'm a much better person when I make time for yoga\n",
      "------------\n",
      "https://t.co/6V9BUBPrZW\n",
      "------------\n",
      "man idk if i feel better or worse i‚Äôm kms\n",
      "------------\n",
      "Is that a true story? #Oregon https://t.co/olV7n6AEaz\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for text in df_SF_01.text[:20]:\n",
    "    print(text)\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                  input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                  min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                  smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                  sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=None, use_idf=True, vocabulary=None)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ecig_LR.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ecig_LR.steps\n",
    "LR_ecig = clf_ecig_LR.steps[1][1]\n",
    "coefficients = LR_ecig.coef_.tolist()[0]\n",
    "print('length of coefficients: ', len(coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of features:  19904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ecig = clf_ecig_LR.get_params()['tfidf']\n",
    "features = tfidf_ecig.get_feature_names()\n",
    "print('length of features: ', len(features))\n",
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>juul</td>\n",
       "      <td>3.204274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17589</th>\n",
       "      <td>vape</td>\n",
       "      <td>2.814391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18016</th>\n",
       "      <td>vaping</td>\n",
       "      <td>1.738162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11014</th>\n",
       "      <td>my</td>\n",
       "      <td>1.016856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>my juul</td>\n",
       "      <td>0.839300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12920</th>\n",
       "      <td>pods</td>\n",
       "      <td>0.780632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>the juul</td>\n",
       "      <td>0.728589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>juul pods</td>\n",
       "      <td>0.634277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10488</th>\n",
       "      <td>me</td>\n",
       "      <td>0.615104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>can</td>\n",
       "      <td>0.579114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>get</td>\n",
       "      <td>0.570759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17950</th>\n",
       "      <td>vapes</td>\n",
       "      <td>0.570529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7236</th>\n",
       "      <td>hit</td>\n",
       "      <td>0.550110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>in</td>\n",
       "      <td>0.544854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>in the</td>\n",
       "      <td>0.501707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19590</th>\n",
       "      <td>you</td>\n",
       "      <td>0.491827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>my vape</td>\n",
       "      <td>0.479689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>hitting</td>\n",
       "      <td>0.463396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13594</th>\n",
       "      <td>rip</td>\n",
       "      <td>0.445243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16779</th>\n",
       "      <td>to</td>\n",
       "      <td>0.436759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18916</th>\n",
       "      <td>when</td>\n",
       "      <td>0.422221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17874</th>\n",
       "      <td>vapenation</td>\n",
       "      <td>0.415354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>juuls</td>\n",
       "      <td>0.402899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>do</td>\n",
       "      <td>0.396484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17655</th>\n",
       "      <td>vape juice</td>\n",
       "      <td>0.395593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>buy</td>\n",
       "      <td>0.391937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17835</th>\n",
       "      <td>vapelife</td>\n",
       "      <td>0.376761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957</th>\n",
       "      <td>juul and</td>\n",
       "      <td>0.376107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>juice</td>\n",
       "      <td>0.374643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>every</td>\n",
       "      <td>0.370848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>hours</td>\n",
       "      <td>-0.325319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18251</th>\n",
       "      <td>vapors</td>\n",
       "      <td>-0.326621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13690</th>\n",
       "      <td>rub</td>\n",
       "      <td>-0.330565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18759</th>\n",
       "      <td>weed</td>\n",
       "      <td>-0.331737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19527</th>\n",
       "      <td>yes</td>\n",
       "      <td>-0.346890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>much</td>\n",
       "      <td>-0.347542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15472</th>\n",
       "      <td>swishers</td>\n",
       "      <td>-0.348019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>by</td>\n",
       "      <td>-0.356983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221</th>\n",
       "      <td>keep</td>\n",
       "      <td>-0.358097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15577</th>\n",
       "      <td>taste</td>\n",
       "      <td>-0.361313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9399</th>\n",
       "      <td>krave</td>\n",
       "      <td>-0.365375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>smokey</td>\n",
       "      <td>-0.371637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9449</th>\n",
       "      <td>kravenlupei</td>\n",
       "      <td>-0.372313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10334</th>\n",
       "      <td>mango</td>\n",
       "      <td>-0.389488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>vapormax</td>\n",
       "      <td>-0.419337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17213</th>\n",
       "      <td>travuseshakawa</td>\n",
       "      <td>-0.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10755</th>\n",
       "      <td>missingpurpleguavapear</td>\n",
       "      <td>-0.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>-0.444528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16505</th>\n",
       "      <td>this</td>\n",
       "      <td>-0.452565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>fruit</td>\n",
       "      <td>-0.526253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11479</th>\n",
       "      <td>nike</td>\n",
       "      <td>-0.556501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>love</td>\n",
       "      <td>-0.585080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>freesmoke</td>\n",
       "      <td>-0.631907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>co</td>\n",
       "      <td>-0.660614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>https</td>\n",
       "      <td>-0.660614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7470</th>\n",
       "      <td>https co</td>\n",
       "      <td>-0.660614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>smoking</td>\n",
       "      <td>-0.713817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12318</th>\n",
       "      <td>orange</td>\n",
       "      <td>-0.729370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>drinking</td>\n",
       "      <td>-0.827552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>smoke</td>\n",
       "      <td>-0.950082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19904 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       features  coefficients\n",
       "8951       juul      3.204274\n",
       "17589      vape      2.814391\n",
       "18016    vaping      1.738162\n",
       "11014        my      1.016856\n",
       "11099   my juul      0.839300\n",
       "...         ...           ...\n",
       "7470   https co     -0.660614\n",
       "14632   smoking     -0.713817\n",
       "12318    orange     -0.729370\n",
       "4713   drinking     -0.827552\n",
       "14399     smoke     -0.950082\n",
       "\n",
       "[19904 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresAndCoef = {'features':features,'coefficients':coefficients}\n",
    "df_featuresAndCoef = pd.DataFrame(featuresAndCoef)\n",
    "df_featuresAndCoef.sort_values(by=['coefficients'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the coefficients seem good, we still got 201606 out of 278884 the classifier said was positive (e-cig relevant), which is not good. How about we include some negative sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkECigaretteInLine(line):\n",
    "    lineInJson = json.loads(line)\n",
    "    textInLine = lineInJson[\"text\"]\n",
    "    lowercaseLine = textInLine.lower()\n",
    "\n",
    "    # Category keyword\n",
    "    synonym_ecig = ['electronic-cigarette', 'electronic cigarette', 'electronic cig', ' e-cig', ' ecig', ' e cig', 'e-cigarette', 'ecigarette', ' e cigarette', 'e-juice', ' ejuice', ' e juice', 'e-liquid', ' eliquid', ' e liquid', 'e-smoke', 'esmoke', ' e smoke', 'vape', 'vaper', 'vaping', 'vape-juice',\n",
    "                    'vape-liquid', ' vapor', 'vaporizer', 'boxmod', 'cloud chaser', 'cloudchaser', 'smoke assist', 'ehookah', 'e-hookah', ' e hookah', 'stillblowingsmoke', 'still blowing smoke', 'cherry tip cigarillo', '#e-cig', '#ecig', '#e cigar', '#ejuice', '#e juice', '#eliquid', '#e liquid', '#vapor', '#ehookah', '#e hookah']\n",
    "    brand_ecig = ['juul', 'vaporfi', 'vype pebble', 'v2 cig', 'v2cigs', 'v2 cigs', 'halocigs', ' njoy', 'markten', 'vuse', 'tryst', 'atomizer', 'cartomizer', 'south beach smoke', 'eversmoke', 'joye510', 'joye 510', 'joyetech', 'logicecig', 'smartsmoker', ' mistic', 'smokestiks', '21st century smoke', 'logic black label',\n",
    "                  ' fin ', ' finiti', 'nicotek', 'cigirex', 'ciga&blu', 'cig&blu', 'logic&cig', 'e-swisher', 'e swisher', 'eswisher', 'ezsmoker', 'ez&cig', 'green smoke', 'cigalectric', 'xhale o2', 'xhaleo2', 'cig2o', 'green smart living', 'greensmartliving', 'krave', 'swisher blk', 'grimmgreen', '#njoy', '#fin ', '#finiti']\n",
    "    policy_ecig = ['sb140', 'sb 140', 'sb24', 'sb 24']\n",
    "    cessation_ecig = ['notblowingsmoke', 'not blowing smoke',\n",
    "                      'tobaccofreekids', 'notareplacement']\n",
    "\n",
    "    # test for synonym\n",
    "    for keyword in synonym_ecig:\n",
    "        #         print(keyword)\n",
    "        if '&' not in keyword and keyword in lowercaseLine:\n",
    "            return True\n",
    "        elif '&' in keyword:\n",
    "            k1, k2 = keyword.split('&')\n",
    "            if k1 in lowercaseLine and k2 in lowercaseLine:\n",
    "                return True\n",
    "\n",
    "            # synonym_ecig_list.append(line)\n",
    "            # flagHit = True\n",
    "            # break\n",
    "\n",
    "    # test for brand\n",
    "    for keyword in brand_ecig:\n",
    "        if keyword in lowercaseLine:\n",
    "            return True\n",
    "            # brand_ecig_list.append(line)\n",
    "            # flagHit = True\n",
    "            # break\n",
    "\n",
    "    # test for policy\n",
    "    for keyword in policy_ecig:\n",
    "        if keyword in lowercaseLine:\n",
    "            return True\n",
    "            # policy_ecig_list.append(line)\n",
    "            # flagHit = True\n",
    "            # break\n",
    "\n",
    "    # test for cessation\n",
    "    for keyword in cessation_ecig:\n",
    "        if keyword in lowercaseLine:\n",
    "            return True\n",
    "            # cessation_ecig_list.append(line)\n",
    "            # flagHit = True\n",
    "            # break\n",
    "\n",
    "    return False\n",
    "\n",
    "def getPlaceName(jsonLine):\n",
    "    #     print(jsonLine['place']['name'])\n",
    "    return jsonLine['place']['name']\n",
    "\n",
    "def checkLocationInLine(line):\n",
    "    try:\n",
    "        tweetInJson = json.loads(line)\n",
    "        tweetPlace = getPlaceName(tweetInJson)\n",
    "        tweetPlace_lowercase = tweetPlace.lower()\n",
    "        if ('san francisco' in tweetPlace_lowercase) or (' SF ' in tweetPlace) or ('sfo' in tweetPlace_lowercase):\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def getNotECigaretteLinesFromFile(fileName):\n",
    "    not_ECigarette_notInSF_Line = set()\n",
    "    with open(fileName, \"r\") as f:\n",
    "        everyLines = f.readlines()\n",
    "        countOfEachFile = 0\n",
    "        for line in everyLines:\n",
    "            # Not in San Francisco & Not include key word\n",
    "            if not checkLocationInLine(line):\n",
    "                if not checkECigaretteInLine(line):\n",
    "                    not_ECigarette_notInSF_Line.add(line)\n",
    "                    countOfEachFile += 1\n",
    "            # Each file we only take 400 lines. 24 files in total.\n",
    "            if countOfEachFile >= 400:\n",
    "                break\n",
    "                \n",
    "    # Write Not E-Cigarette in not SF area data to local file\n",
    "    not_ECigarette_fileName = '/mnt/volume/result/juliana_NOT_ECigarette_2018_01.json'\n",
    "    with open(not_ECigarette_fileName, \"a\", encoding=\"utf-8\") as f:\n",
    "        for line in not_ECigarette_notInSF_Line:\n",
    "            f.write(str(line))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_16h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_00h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_06h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_05h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_07h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_19h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_13h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_20h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_15h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_02h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_21h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_08h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_09h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_01h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_12h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_23h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_04h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_11h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_17h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_14h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_03h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_10h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_18h.json\n",
      "finish file:  /mnt/volume/juliana/data/2018-01-10//twitter_2018-01-10_22h.json\n"
     ]
    }
   ],
   "source": [
    "negative_directoryPath = '/mnt/volume/juliana/data/2018-01-10/'\n",
    "\n",
    "# go through each file\n",
    "files = os.listdir(negative_directoryPath)\n",
    "for file in files:\n",
    "#     print(file)\n",
    "    file = negative_directoryPath + '/' + file\n",
    "    if not os.path.isdir(file) and (os.path.splitext(file)[-1] == \".json\"):\n",
    "#         print(file)\n",
    "        getNotECigaretteLinesFromFile(file)\n",
    "        print('finish file: ', file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the data to see how many lines in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_ECigarette_filePath = '/mnt/volume/result/juliana_NOT_ECigarette_2018_01.json'\n",
    "df_not_ECigarette_01 = pd.read_json(not_ECigarette_filePath, lines=True, encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filter_level</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>truncated</th>\n",
       "      <th>lang</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>id</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>favorited</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>id_str</th>\n",
       "      <th>user</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CuteEmergency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>und</td>\n",
       "      <td>9.509164e+17</td>\n",
       "      <td>951196965999607810</td>\n",
       "      <td>{'media': [{'sizes': {'thumb': {'w': 80, 'resi...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>568825492.0</td>\n",
       "      <td>0</td>\n",
       "      <td>951196965999607808</td>\n",
       "      <td>{'location': 'Nashville, TN', 'default_profile...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>951196952540008448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>951196952540008448</td>\n",
       "      <td>{'location': 'West Coast', 'default_profile': ...</td>\n",
       "      <td>{'extended_entities': {'media': [{'sizes': {'s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>951196971028631553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>951196971028631552</td>\n",
       "      <td>{'location': 'Minneapolis, MN', 'default_profi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.511767e+17</td>\n",
       "      <td>9.511767e+17</td>\n",
       "      <td>{'filter_level': 'low', 'quote_count': 45, 're...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  filter_level  quote_count  retweeted in_reply_to_screen_name  \\\n",
       "0          low            0      False           CuteEmergency   \n",
       "1          low            0      False                    None   \n",
       "2          low            0      False                    None   \n",
       "\n",
       "   possibly_sensitive  truncated lang  in_reply_to_status_id_str  \\\n",
       "0                 0.0      False  und               9.509164e+17   \n",
       "1                 0.0       True   en                        NaN   \n",
       "2                 0.0      False   en                        NaN   \n",
       "\n",
       "                   id                                  extended_entities  ...  \\\n",
       "0  951196965999607810  {'media': [{'sizes': {'thumb': {'w': 80, 'resi...  ...   \n",
       "1  951196952540008448                                                NaN  ...   \n",
       "2  951196971028631553                                                NaN  ...   \n",
       "\n",
       "                                              source favorited  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...     False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...     False   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...     False   \n",
       "\n",
       "   in_reply_to_user_id retweet_count              id_str  \\\n",
       "0          568825492.0             0  951196965999607808   \n",
       "1                  NaN             0  951196952540008448   \n",
       "2                  NaN             0  951196971028631552   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'location': 'Nashville, TN', 'default_profile...   \n",
       "1  {'location': 'West Coast', 'default_profile': ...   \n",
       "2  {'location': 'Minneapolis, MN', 'default_profi...   \n",
       "\n",
       "                                      extended_tweet quoted_status_id_str  \\\n",
       "0                                                NaN                  NaN   \n",
       "1  {'extended_entities': {'media': [{'sizes': {'s...                  NaN   \n",
       "2                                                NaN         9.511767e+17   \n",
       "\n",
       "  quoted_status_id                                      quoted_status  \n",
       "0              NaN                                                NaN  \n",
       "1              NaN                                                NaN  \n",
       "2     9.511767e+17  {'filter_level': 'low', 'quote_count': 45, 're...  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_ECigarette_01[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filter_level', 'quote_count', 'retweeted', 'in_reply_to_screen_name',\n",
       "       'possibly_sensitive', 'truncated', 'lang', 'in_reply_to_status_id_str',\n",
       "       'id', 'extended_entities', 'in_reply_to_user_id_str', 'timestamp_ms',\n",
       "       'in_reply_to_status_id', 'created_at', 'favorite_count',\n",
       "       'display_text_range', 'place', 'coordinates', 'text', 'contributors',\n",
       "       'geo', 'reply_count', 'entities', 'is_quote_status', 'source',\n",
       "       'favorited', 'in_reply_to_user_id', 'retweet_count', 'id_str', 'user',\n",
       "       'extended_tweet', 'quoted_status_id_str', 'quoted_status_id',\n",
       "       'quoted_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_ECigarette_01.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         @CuteEmergency Awwww https://t.co/yY8f7Y3zHc\n",
       "1    This barefoot flip-flop or notices me filming ...\n",
       "2    Who's going to be Ramirez's understudy now? üíÖ ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_ECigarette_01.text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We generated 9555 negative tweets.\n",
      "We got 10557 labels in total, among which 571 of them are positive (e-cig relevant)\n",
      "length of X_train:  8445\n",
      "length of X_test:  2112\n",
      "length of y_train:  8445\n",
      "length of y_test:  2112\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "# filePath = \"C:/Users/eddie/Desktop/Prof. Rumi Chunara/alcohol/data/labeled_figure_eight_csv_1000.csv\"\n",
    "filePath = \"/mnt/volume/labeled_data/labeled_figure_eight_csv_1000.csv\"\n",
    "df_labeled = pd.read_csv(filePath)\n",
    "# df_labeled.is_this_posting_relevant_to_ecigarette[:3]\n",
    "\n",
    "# Deal with ecig_labels.\n",
    "ecig_labels = []\n",
    "# extracting pre-labeled classification\n",
    "for i in range(0,len(df_labeled.is_this_posting_relevant_to_ecigarette)):\n",
    "#     print(df.is_this_posting_relevant_to_ecigarette[i])\n",
    "    if df_labeled.is_this_posting_relevant_to_ecigarette[i] == 'ECIG':\n",
    "        ecig_labels.append(1)\n",
    "    elif df_labeled.is_this_posting_relevant_to_ecigarette[i] == 'NOT-ECIG':\n",
    "        ecig_labels.append(0)\n",
    "    else:\n",
    "        print('Should not go to here')\n",
    "# ecig_labels\n",
    "\n",
    "# Deal with negative tweets.\n",
    "print('We generated %d negative tweets.' % (len(df_not_ECigarette_01)))\n",
    "label_not_ECigarette = [0]*len(df_not_ECigarette_01)\n",
    "ecig_labels.extend(label_not_ECigarette)\n",
    "print('We got %d labels in total, among which %d of them are positive (e-cig relevant)' % (len(ecig_labels), sum(ecig_labels)))\n",
    "\n",
    "# Combine the two data frame\n",
    "series_textFromLabeled = df_labeled.realdonaldtrump_foxandfriends_smoke_blowing_up_your_orange_ass\n",
    "series_textFromGenerated = df_not_ECigarette_01.text\n",
    "series_combined = series_textFromLabeled.append(series_textFromGenerated, ignore_index=True)\n",
    "# df_combined = pd.concat(df_labeled.realdonaldtrump_foxandfriends_smoke_blowing_up_your_orange_ass, df_not_ECigarette_01.text)\n",
    "# len(series_combined)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(series_combined, ecig_labels, test_size=0.2, random_state=26)\n",
    "print('length of X_train: ', len(X_train))\n",
    "print('length of X_test: ', len(X_test))\n",
    "print('length of y_train: ', len(y_train))\n",
    "print('length of y_test: ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                  input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                  min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                  smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                  sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=None, use_idf=True, vocabulary=None)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR\n",
    "clf_ecig_LR = ECigPipeline().pipeline(LogisticRegression())\n",
    "clf_ecig_LR.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/yijun/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ecig_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  2112\n",
      "96 different item in whole dataset\n",
      "accuracy: 95.454545%\n",
      "F1 Score:  0.36\n",
      "alcohol LR AUC:  0.9443688252870462\n"
     ]
    }
   ],
   "source": [
    "# predict in testing set.\n",
    "y_ecig_LR = clf_ecig_LR.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_ecig_LR, y_test)\n",
    "f1_score_LR = computeF1Score(y_test, y_ecig_LR)\n",
    "print('F1 Score: ', f1_score_LR)\n",
    "auc_score_LR = computeAUC(clf_ecig_LR, X_test, y_test, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('alcohol LR AUC: ', auc_score_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_filePath = '/mnt/volume/result/juliana_allSF_2018_01.json'\n",
    "df_SF_01 = pd.read_json(SF_filePath, lines=True, encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of San Francisco data:  278884\n",
      "How many of them the classifier said is positive (e-cig relevant)?:  11\n"
     ]
    }
   ],
   "source": [
    "print('length of San Francisco data: ', len(df_SF_01))\n",
    "y_SF_LR = clf_ecig_LR.predict(df_SF_01.text)\n",
    "print('How many of them the classifier said is positive (e-cig relevant)?: ',sum(y_SF_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Echan419 Vape lung bubbles\n",
      "-----------\n",
      "You want some of this Juul ?\n",
      "\n",
      "-Me never smoking a day in my life and passing around tequila shots instead of a Juul.\n",
      "-----------\n",
      "You want some of this Juul ?\n",
      "\n",
      "-Me never smoking tobacco a day in my life and passing around tequila shots instead of a Juul.\n",
      "-----------\n",
      "Your mcm shames me for smoking two cigarettes a day but he goes through 3 Juul pods a day\n",
      "-----------\n",
      "@thegreaatdane Same but with my juul.\n",
      "-----------\n",
      "@SweetxSauce @jnudey get a juul, you‚Äôll look cooler\n",
      "-----------\n",
      "i lost my juul charger !!! üíÜüèΩ‚Äç‚ôÇÔ∏è\n",
      "-----------\n",
      "BUD-DEX CBD VAPE PEN\n",
      "#buddyvape #vapepens #vapelife #vapershouts #vapereviews #vapepen #vapeshop #vaping #smokeshop‚Ä¶ https://t.co/1kcjTT2u66\n",
      "-----------\n",
      "My Vape fell out of my pocket on BART. Long shot, but did anyone find it? #Vape #BART #SF #SanFrancisco\n",
      "-----------\n",
      "Omg mango Juul pods are a game changer üòã\n",
      "-----------\n",
      "RIP my Green Smart Living (JUUL) hoe only lasted 2 weeks :+(\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "index_in_df_SF = np.where(y_SF_LR)[0]\n",
    "for text in df_SF_01.iloc[index_in_df_SF,].text:\n",
    "    print(text)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of coefficients:  152619\n"
     ]
    }
   ],
   "source": [
    "clf_ecig_LR.steps\n",
    "LR_ecig = clf_ecig_LR.steps[1][1]\n",
    "coefficients = LR_ecig.coef_.tolist()[0]\n",
    "print('length of coefficients: ', len(coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of features:  152619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ecig = clf_ecig_LR.get_params()['tfidf']\n",
    "features = tfidf_ecig.get_feature_names()\n",
    "print('length of features: ', len(features))\n",
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76271</th>\n",
       "      <td>juul</td>\n",
       "      <td>10.134187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138820</th>\n",
       "      <td>vape</td>\n",
       "      <td>10.018277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139248</th>\n",
       "      <td>vaping</td>\n",
       "      <td>4.995269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90920</th>\n",
       "      <td>my juul</td>\n",
       "      <td>2.253609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139340</th>\n",
       "      <td>vapor</td>\n",
       "      <td>2.137005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117120</th>\n",
       "      <td>smoke</td>\n",
       "      <td>2.116950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11873</th>\n",
       "      <td>and</td>\n",
       "      <td>2.036225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104191</th>\n",
       "      <td>pods</td>\n",
       "      <td>1.978481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90287</th>\n",
       "      <td>my</td>\n",
       "      <td>1.789591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127002</th>\n",
       "      <td>the juul</td>\n",
       "      <td>1.759060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91377</th>\n",
       "      <td>my vape</td>\n",
       "      <td>1.568763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61355</th>\n",
       "      <td>hit</td>\n",
       "      <td>1.518361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76396</th>\n",
       "      <td>juul pods</td>\n",
       "      <td>1.448818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139193</th>\n",
       "      <td>vapes</td>\n",
       "      <td>1.415056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76486</th>\n",
       "      <td>juuls</td>\n",
       "      <td>1.412834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49031</th>\n",
       "      <td>flavor</td>\n",
       "      <td>1.298920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117373</th>\n",
       "      <td>smoking</td>\n",
       "      <td>1.263496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75583</th>\n",
       "      <td>juice</td>\n",
       "      <td>1.256518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139114</th>\n",
       "      <td>vapenation</td>\n",
       "      <td>1.210832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138884</th>\n",
       "      <td>vape juice</td>\n",
       "      <td>1.178297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76470</th>\n",
       "      <td>juuling</td>\n",
       "      <td>1.126541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125732</th>\n",
       "      <td>the</td>\n",
       "      <td>1.091744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76278</th>\n",
       "      <td>juul and</td>\n",
       "      <td>1.056617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139067</th>\n",
       "      <td>vapelife</td>\n",
       "      <td>1.054874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61427</th>\n",
       "      <td>hitting</td>\n",
       "      <td>1.009749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144162</th>\n",
       "      <td>when</td>\n",
       "      <td>0.924009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92756</th>\n",
       "      <td>new</td>\n",
       "      <td>0.888850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139159</th>\n",
       "      <td>vapeporn</td>\n",
       "      <td>0.887615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49083</th>\n",
       "      <td>flavored</td>\n",
       "      <td>0.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96387</th>\n",
       "      <td>of juul</td>\n",
       "      <td>0.880594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147175</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.392701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83265</th>\n",
       "      <td>love</td>\n",
       "      <td>-0.408676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123922</th>\n",
       "      <td>temp</td>\n",
       "      <td>-0.409273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145838</th>\n",
       "      <td>wind mph</td>\n",
       "      <td>-0.411593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108355</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>-0.422092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100221</th>\n",
       "      <td>our latest</td>\n",
       "      <td>-0.422224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130719</th>\n",
       "      <td>this job</td>\n",
       "      <td>-0.430497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79245</th>\n",
       "      <td>latest</td>\n",
       "      <td>-0.438961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60734</th>\n",
       "      <td>high 18</td>\n",
       "      <td>-0.443032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89698</th>\n",
       "      <td>mph</td>\n",
       "      <td>-0.477282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2018</td>\n",
       "      <td>-0.484544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18587</th>\n",
       "      <td>barometer</td>\n",
       "      <td>-0.496474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>2018 01</td>\n",
       "      <td>-0.506557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67191</th>\n",
       "      <td>humidity</td>\n",
       "      <td>-0.533380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124097</th>\n",
       "      <td>temperature</td>\n",
       "      <td>-0.536632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107887</th>\n",
       "      <td>re</td>\n",
       "      <td>-0.539818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>-0.599693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>01</td>\n",
       "      <td>-0.604054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19208</th>\n",
       "      <td>be</td>\n",
       "      <td>-0.656313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107500</th>\n",
       "      <td>rain today</td>\n",
       "      <td>-0.660310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134258</th>\n",
       "      <td>today</td>\n",
       "      <td>-0.728909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61086</th>\n",
       "      <td>hiring</td>\n",
       "      <td>-0.778900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107457</th>\n",
       "      <td>rain</td>\n",
       "      <td>-0.779061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.836287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145676</th>\n",
       "      <td>wind</td>\n",
       "      <td>-0.906742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74761</th>\n",
       "      <td>job</td>\n",
       "      <td>-0.926609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130346</th>\n",
       "      <td>this</td>\n",
       "      <td>-0.951651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62872</th>\n",
       "      <td>https co</td>\n",
       "      <td>-1.367781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62871</th>\n",
       "      <td>https</td>\n",
       "      <td>-1.367781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29604</th>\n",
       "      <td>co</td>\n",
       "      <td>-1.395496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152619 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  coefficients\n",
       "76271       juul     10.134187\n",
       "138820      vape     10.018277\n",
       "139248    vaping      4.995269\n",
       "90920    my juul      2.253609\n",
       "139340     vapor      2.137005\n",
       "...          ...           ...\n",
       "74761        job     -0.926609\n",
       "130346      this     -0.951651\n",
       "62872   https co     -1.367781\n",
       "62871      https     -1.367781\n",
       "29604         co     -1.395496\n",
       "\n",
       "[152619 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresAndCoef = {'features':features,'coefficients':coefficients}\n",
    "df_featuresAndCoef = pd.DataFrame(featuresAndCoef)\n",
    "df_featuresAndCoef.sort_values(by=['coefficients'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
