{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.LocalWebserverAuth()\n",
    "\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list = drive.ListFile({'q': \"'root' in parents\"}).GetList()\n",
    "# for file1 in file_list:\n",
    "#     print('title: {}, id: {}'.format(file1['title'], file1['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipTarGzFile(fileName):\n",
    "    if fileName.endswith(\"tar.gz\"):\n",
    "        tar = tarfile.open(fileName, \"r:gz\")\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        print('Successfully extracted file %s ' %(fileName))\n",
    "    elif fileName.endswith(\"tar\"):\n",
    "        tar = tarfile.open(fileName, \"r:\")\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        print('Successfully extracted file %s ' %(fileName))\n",
    "    else:\n",
    "        print('Please check the suffix of file %s ' %(fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted file 2016-05-03/twitter_2016-05-03_17h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_00h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_01h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_02h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_03h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_04h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_05h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_06h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_07h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_08h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_09h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_10h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_11h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_12h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_13h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_14h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_15h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_16h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_17h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_18h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_19h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_20h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_21h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_22h.json.tar.gz \n",
      "Successfully extracted file 2016-05-10/twitter_2016-05-10_23h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_00h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_01h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_02h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_03h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_04h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_05h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_06h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_07h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_08h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_09h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_10h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_11h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_12h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_13h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_14h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_15h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_16h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_17h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_18h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_19h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_20h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_21h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_22h.json.tar.gz \n",
      "Successfully extracted file 2016-05-28/twitter_2016-05-28_23h.json.tar.gz \n",
      "Successfully extracted file 2016-05-30/twitter_2016-05-30_09h.json.tar.gz \n"
     ]
    }
   ],
   "source": [
    "# We change to the directory where we want our data stored.\n",
    "os.chdir('F:/Twitter data/Juliana/')\n",
    "# fileName = '2017_01_06_19.tar.gz'\n",
    "\n",
    "# Iterate the directory to find the file that need unzip.\n",
    "jsonFileDirectoryPath = \"F:/Twitter data/Juliana/\"\n",
    "dirNames= os.listdir(jsonFileDirectoryPath)\n",
    "# Create a list to store SF tweets\n",
    "SF_tweets = []\n",
    "\n",
    "    \n",
    "for dirName in dirNames:\n",
    "#     print(dirName)\n",
    "    files= os.listdir(dirName)\n",
    "    for file in files:\n",
    "#         print(file)\n",
    "        file = dirName + '/' +file\n",
    "#         print(file)\n",
    "        # Make sure we unzip the file that need to be unziped and not directory.\n",
    "        if not os.path.isdir(file) and (os.path.splitext(file)[-1] == \".gz\" or os.path.splitext(file)[-1] == \".tar\"):\n",
    "            unzipTarGzFile(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
