{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# print(os.getcwd())\n",
    "os.chdir('C:/Users/eddie/Desktop/Prof. Rumi Chunara/alcohol')\n",
    "import pickle\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas\n",
    "import numpy as np\n",
    "import sys\n",
    "from evaluation.metric import computeAccuracy, computeF1Score, computeAUC, computeAUCBehavior\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import uniform\n",
    "# %reload_ext pipelines.alcohol.AlcoholPipeline\n",
    "from pipelines.alcohol import AlcoholPipeline\n",
    "from sklearn.grid_search import RandomizedSearchCV, GridSearchCV\n",
    "from scripts.gridsearch import text_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_alc_initial = pickle.load(open('./alcohol classifiers/clf_alc_UPDATED.p', 'rb'))\n",
    "# clf_fpa_initial = pickle.load(open('./alcohol classifiers/clf_fpa_UPDATED.p', 'rb'))\n",
    "clf_behavior_initial = pickle.load(open('./alcohol classifiers/clf_fpl_double_labeled', 'rb'))\n",
    "df = pandas.read_csv(\"./data/alcohol_training_instances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the behavior level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2, 2, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "length of first person level labels:  6357\n",
      "[0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "length of first person level index in df:  15651\n",
      "[2, 5, 6, 7, 11, 13, 17, 18, 21, 22, 23, 24, 26, 27, 28]\n",
      "length of first person level df index:  6357\n"
     ]
    }
   ],
   "source": [
    "# appending labels based on whether tweet label contains phrase\n",
    "behavior_labels = []\n",
    "behavior_index_in_df = []\n",
    "\n",
    "fpl = \"'first_person_level'\"\n",
    "\n",
    "# extracting FP levels and constructing subset vector simultaneously\n",
    "for i in range(len(df)):\n",
    "    if fpl in df.labels[i]:\n",
    "        behavior_labels.append(int(df.labels[i][df.labels[i].find(fpl) + len(fpl) + 2]))\n",
    "        behavior_index_in_df.append(1)\n",
    "    else:\n",
    "        behavior_index_in_df.append(0)\n",
    "\n",
    "behavior_labels = list(map(int, behavior_labels))\n",
    "print(behavior_labels[:20])\n",
    "# print(subset_vec_alc_fp[:10])\n",
    "print('length of first person level labels: ', len(behavior_labels)) # 6357\n",
    "print(behavior_index_in_df[:20])\n",
    "print('length of first person level index in df: ', len(behavior_index_in_df)) # 15651\n",
    "index_behavior = list(np.where(behavior_index_in_df)[0])\n",
    "print(index_behavior[:15])\n",
    "print('length of first person level df index: ', len(index_behavior)) # 6357\n",
    "df_behavior = df.iloc[index_behavior,]\n",
    "# df_fp.head\n",
    "# fp_labels = np.asarray(fp_labels)\n",
    "\n",
    "# change label 3 to label 0\n",
    "behavior_labels = [0 if x == 3 else x for x in behavior_labels] \n",
    "\n",
    "# train test dataset split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_behavior, behavior_labels, test_size=0.2, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357\n",
      "15651\n"
     ]
    }
   ],
   "source": [
    "print(len(behavior_labels))\n",
    "print(len(behavior_index_in_df))\n",
    "# behavior_labels[:30]\n",
    "# for i in behavior_labels:\n",
    "#     if i ==3:\n",
    "#         print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model for the following grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "      ...      token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None))]))],\n",
       "         transformer_weights=None)),\n",
       " ('scaler', Normalizer(copy=True, norm='l2')),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR\n",
    "clf_behavior_LR = AlcoholPipeline(global_features=[\"text\"]).pipeline(LogisticRegression())\n",
    "clf_behavior_LR.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=T...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_behavior_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are trying to implement grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__C': uniform(0.0001, 1000),\n",
    "    'clf__penalty': ['l2', \"l1\"],\n",
    "#     'clf__penalty': ['l2'],\n",
    "    'clf__tol': uniform(0.0001, 0.001),\n",
    "#     'clf__verbose': [0]\n",
    "#     'features__text__tfidf__analyzer': ['char'],\n",
    "#     'features__text__tfidf__ngram_range': [(2,5)]\n",
    "}\n",
    "\n",
    "param_grid.update(text_grid)\n",
    "\n",
    "cv_kwargs = dict(\n",
    "    n_iter=5,\n",
    "    scoring=None,\n",
    "    fit_params=None,\n",
    "    n_jobs=-1,\n",
    "    iid=True,\n",
    "    refit=True,\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    pre_dispatch='2*n_jobs',\n",
    "    error_score=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_behavior_LR_grid = RandomizedSearchCV(clf_behavior_LR, param_grid, **cv_kwargs)\n",
    "clf_behavior_LR_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best estimator \n",
    "best_estimator_LR = clf_behavior_LR_grid.best_estimator_\n",
    "print('best estimator: ', best_estimator_LR)\n",
    "print('-------------------------- mean accuracy on the cross validation of best estimator --------------------------')\n",
    "print('best score: ', clf_behavior_LR_grid.best_score_)\n",
    "print('best score related parameters: ', clf_behavior_LR_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the best estimator performance on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in testing set.\n",
    "y_behavior_LR_grid = best_estimator_LR.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_behavior_LR_grid, y_test)\n",
    "f1_score_LR_grid = computeF1Score(y_test, y_behavior_LR_grid, average = None)\n",
    "print('F1 Score: ', f1_score_LR_grid)\n",
    "auc_score_LR_grid = computeAUCBehavior(best_estimator_LR, X_test, y_test, plot=False)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('LR classifier AUC: ', auc_score_LR_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
