{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# print(os.getcwd())\n",
    "os.chdir('C:/Users/eddie/Desktop/Prof. Rumi Chunara/alcohol')\n",
    "import pickle\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from evaluation.metric import computeAccuracy, computeF1Score, computeAUC, computeAUCBehavior\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import uniform\n",
    "# %reload_ext pipelines.alcohol.AlcoholPipeline\n",
    "from pipelines.alcohol import AlcoholPipeline\n",
    "from sklearn.grid_search import RandomizedSearchCV, GridSearchCV\n",
    "from scripts.gridsearch import text_grid\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_alc_initial = pickle.load(open('./alcohol classifiers/clf_alc_UPDATED.p', 'rb'))\n",
    "# clf_fpa_initial = pickle.load(open('./alcohol classifiers/clf_fpa_UPDATED.p', 'rb'))\n",
    "clf_behavior_initial = pickle.load(open('./alcohol classifiers/clf_fpl_double_labeled', 'rb'))\n",
    "df = pd.read_csv(\"./data/alcohol_training_instances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the behavior level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2, 2, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "length of first person level labels:  6357\n",
      "[0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "length of first person level index in df:  15651\n",
      "[2, 5, 6, 7, 11, 13, 17, 18, 21, 22, 23, 24, 26, 27, 28]\n",
      "length of first person level df index:  6357\n"
     ]
    }
   ],
   "source": [
    "# appending labels based on whether tweet label contains phrase\n",
    "behavior_labels = []\n",
    "behavior_index_in_df = []\n",
    "\n",
    "fpl = \"'first_person_level'\"\n",
    "\n",
    "# extracting FP levels and constructing subset vector simultaneously\n",
    "for i in range(len(df)):\n",
    "    if fpl in df.labels[i]:\n",
    "        behavior_labels.append(int(df.labels[i][df.labels[i].find(fpl) + len(fpl) + 2]))\n",
    "        behavior_index_in_df.append(1)\n",
    "    else:\n",
    "        behavior_index_in_df.append(0)\n",
    "\n",
    "behavior_labels = list(map(int, behavior_labels))\n",
    "print(behavior_labels[:20])\n",
    "# print(subset_vec_alc_fp[:10])\n",
    "print('length of first person level labels: ', len(behavior_labels)) # 6357\n",
    "print(behavior_index_in_df[:20])\n",
    "print('length of first person level index in df: ', len(behavior_index_in_df)) # 15651\n",
    "index_behavior = list(np.where(behavior_index_in_df)[0])\n",
    "print(index_behavior[:15])\n",
    "print('length of first person level df index: ', len(index_behavior)) # 6357\n",
    "df_behavior = df.iloc[index_behavior,]\n",
    "# df_fp.head\n",
    "# fp_labels = np.asarray(fp_labels)\n",
    "\n",
    "# change label 3 to label 0\n",
    "behavior_labels = [0 if x == 3 else x for x in behavior_labels] \n",
    "\n",
    "# train test dataset split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_behavior, behavior_labels, test_size=0.2, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357\n",
      "15651\n"
     ]
    }
   ],
   "source": [
    "print(len(behavior_labels))\n",
    "print(len(behavior_index_in_df))\n",
    "# behavior_labels[:30]\n",
    "# for i in behavior_labels:\n",
    "#     if i ==3:\n",
    "#         print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model for the following grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "      ...      token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None))]))],\n",
       "         transformer_weights=None)),\n",
       " ('scaler', Normalizer(copy=True, norm='l2')),\n",
       " ('clf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF\n",
    "clf_behavior_RF = AlcoholPipeline(global_features=[\"text\"]).pipeline(RandomForestClassifier())\n",
    "clf_behavior_RF.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=T...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_behavior_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are trying to implement grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_behavior_RF.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "#     'clf__C': uniform(0.0001, 1000),\n",
    "#     'clf__penalty': ['l2', \"l1\"],\n",
    "#     'clf__penalty': ['l2'],\n",
    "#     'clf__tol': uniform(0.0001, 0.001),\n",
    "#     'clf__verbose': [0]\n",
    "#     'features__text__tfidf__analyzer': ['char'],\n",
    "#     'features__text__tfidf__ngram_range': [(2,5)]\n",
    "}\n",
    "\n",
    "param_grid.update(text_grid)\n",
    "\n",
    "cv_kwargs = dict(\n",
    "    n_iter=50,\n",
    "    scoring=None,\n",
    "    fit_params=None,\n",
    "    n_jobs=-1,\n",
    "    iid=True,\n",
    "    refit=True,\n",
    "    cv=10,\n",
    "    verbose=0,\n",
    "    pre_dispatch='2*n_jobs',\n",
    "    error_score=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=0,\n",
       "          estimator=Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=T...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'features__text__tfidf__analyzer': ['char', 'word'], 'features__text__tfidf__lowercase': [False, True], 'features__text__tfidf__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000025BAE1609B0>, 'features__text__tfidf__min_df': <scipy.stats._distn_infrast..., 'english'], 'features__text__tfidf__tokenizer': [None, <function tokenize at 0x0000025BAE220EA0>]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_behavior_RF_grid = RandomizedSearchCV(clf_behavior_RF, param_grid, **cv_kwargs)\n",
    "clf_behavior_RF_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator:  Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('text', Pipeline(steps=[('getter', ItemGetter(key='text')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=T...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n",
      "-------------------------- mean accuracy on the cross validation of best estimator --------------------------\n",
      "best score:  0.6033431661750246\n",
      "best score related parameters:  {'features__text__tfidf__analyzer': 'word', 'features__text__tfidf__lowercase': True, 'features__text__tfidf__max_features': 86709, 'features__text__tfidf__min_df': 1, 'features__text__tfidf__ngram_range': (2, 5), 'features__text__tfidf__norm': 'l2', 'features__text__tfidf__stop_words': None, 'features__text__tfidf__tokenizer': <function tokenize at 0x0000025BAE220EA0>}\n"
     ]
    }
   ],
   "source": [
    "# get the best estimator \n",
    "best_estimator_RF = clf_behavior_RF_grid.best_estimator_\n",
    "print('best estimator: ', best_estimator_RF)\n",
    "print('-------------------------- mean accuracy on the cross validation of best estimator --------------------------')\n",
    "print('best score: ', clf_behavior_RF_grid.best_score_)\n",
    "print('best score related parameters: ', clf_behavior_RF_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the best estimator performance on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  1272\n",
      "511 different item in whole dataset\n",
      "accuracy: 59.827044%\n",
      "F1 Score:  [0.70996785 0.50080775 0.29189189]\n",
      "RF classifier AUC:  {'current': 0.729341888493887, 'looking': 0.7399994451414426, 'reflecting': 0.6819647912380304, 'micro': 0.7646731982516515, 'macro': 0.7173064826593593}\n"
     ]
    }
   ],
   "source": [
    "# predict in testing set.\n",
    "y_behavior_RF_grid = best_estimator_RF.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_behavior_RF_grid, y_test)\n",
    "f1_score_RF_grid = computeF1Score(y_test, y_behavior_RF_grid, average = None)\n",
    "print('F1 Score: ', f1_score_RF_grid)\n",
    "auc_score_RF_grid = computeAUCBehavior(best_estimator_RF, X_test, y_test, plot=False, RF=True)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('RF classifier AUC: ', auc_score_RF_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./alcohol classifiers/behaviorBestEstimatorRF.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_estimator_RF, './alcohol classifiers/behaviorBestEstimatorRF.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the grid search result in table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean_validation_score</th>\n",
       "      <th>cv_validation_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.597640</td>\n",
       "      <td>[0.6019607843137255, 0.6019607843137255, 0.589...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.592527</td>\n",
       "      <td>[0.596078431372549, 0.6098039215686275, 0.5579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.591150</td>\n",
       "      <td>[0.6215686274509804, 0.5941176470588235, 0.565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.597050</td>\n",
       "      <td>[0.6313725490196078, 0.6058823529411764, 0.581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.559489</td>\n",
       "      <td>[0.5431372549019607, 0.5450980392156862, 0.559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.547296</td>\n",
       "      <td>[0.5372549019607843, 0.5392156862745098, 0.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.603343</td>\n",
       "      <td>[0.6137254901960785, 0.5941176470588235, 0.612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.586234</td>\n",
       "      <td>[0.5882352941176471, 0.5980392156862745, 0.593...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.554376</td>\n",
       "      <td>[0.5176470588235295, 0.5568627450980392, 0.573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.587807</td>\n",
       "      <td>[0.5980392156862745, 0.5862745098039216, 0.587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.573058</td>\n",
       "      <td>[0.5941176470588235, 0.5666666666666667, 0.544...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.553392</td>\n",
       "      <td>[0.5529411764705883, 0.5450980392156862, 0.540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.569125</td>\n",
       "      <td>[0.5843137254901961, 0.592156862745098, 0.5481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.600197</td>\n",
       "      <td>[0.5803921568627451, 0.6019607843137255, 0.607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.520944</td>\n",
       "      <td>[0.5490196078431373, 0.5313725490196078, 0.508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.558112</td>\n",
       "      <td>[0.5647058823529412, 0.5215686274509804, 0.555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.585251</td>\n",
       "      <td>[0.592156862745098, 0.6039215686274509, 0.5933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>[0.5392156862745098, 0.5411764705882353, 0.528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.514454</td>\n",
       "      <td>[0.5392156862745098, 0.5058823529411764, 0.528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.588594</td>\n",
       "      <td>[0.5941176470588235, 0.5980392156862745, 0.579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.564012</td>\n",
       "      <td>[0.5764705882352941, 0.5627450980392157, 0.573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.578761</td>\n",
       "      <td>[0.592156862745098, 0.5823529411764706, 0.5540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.601770</td>\n",
       "      <td>[0.6274509803921569, 0.5843137254901961, 0.587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.562832</td>\n",
       "      <td>[0.5627450980392157, 0.5627450980392157, 0.554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.566568</td>\n",
       "      <td>[0.596078431372549, 0.5294117647058824, 0.5461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.593707</td>\n",
       "      <td>[0.5823529411764706, 0.615686274509804, 0.5697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.562832</td>\n",
       "      <td>[0.5568627450980392, 0.5450980392156862, 0.565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.559489</td>\n",
       "      <td>[0.5647058823529412, 0.5843137254901961, 0.587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.590560</td>\n",
       "      <td>[0.6019607843137255, 0.6058823529411764, 0.597...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.595084</td>\n",
       "      <td>[0.5745098039215686, 0.592156862745098, 0.5717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.554966</td>\n",
       "      <td>[0.5549019607843138, 0.5647058823529412, 0.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.594887</td>\n",
       "      <td>[0.6058823529411764, 0.596078431372549, 0.5540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.565978</td>\n",
       "      <td>[0.5901960784313726, 0.5529411764705883, 0.565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.519371</td>\n",
       "      <td>[0.5333333333333333, 0.5196078431372549, 0.510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.570501</td>\n",
       "      <td>[0.5862745098039216, 0.5882352941176471, 0.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.566765</td>\n",
       "      <td>[0.596078431372549, 0.5725490196078431, 0.5618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.569715</td>\n",
       "      <td>[0.5705882352941176, 0.5725490196078431, 0.579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.564602</td>\n",
       "      <td>[0.5725490196078431, 0.5941176470588235, 0.550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.540020</td>\n",
       "      <td>[0.5215686274509804, 0.5372549019607843, 0.550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.518387</td>\n",
       "      <td>[0.5117647058823529, 0.4980392156862745, 0.500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.593314</td>\n",
       "      <td>[0.5941176470588235, 0.5980392156862745, 0.581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.516618</td>\n",
       "      <td>[0.5, 0.5549019607843138, 0.5343811394891945, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.519567</td>\n",
       "      <td>[0.5568627450980392, 0.492156862745098, 0.5225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.588594</td>\n",
       "      <td>[0.5843137254901961, 0.5803921568627451, 0.603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.582694</td>\n",
       "      <td>[0.5745098039215686, 0.596078431372549, 0.6031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'word', 'f...</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>[0.5470588235294118, 0.5431372549019607, 0.546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.588987</td>\n",
       "      <td>[0.6254901960784314, 0.5941176470588235, 0.581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.590167</td>\n",
       "      <td>[0.596078431372549, 0.5823529411764706, 0.5717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.592527</td>\n",
       "      <td>[0.6098039215686275, 0.596078431372549, 0.5343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'features__text__tfidf__analyzer': 'char', 'f...</td>\n",
       "      <td>0.569715</td>\n",
       "      <td>[0.5784313725490197, 0.5745098039215686, 0.546...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           parameters  mean_validation_score  \\\n",
       "0   {'features__text__tfidf__analyzer': 'char', 'f...               0.597640   \n",
       "1   {'features__text__tfidf__analyzer': 'char', 'f...               0.592527   \n",
       "2   {'features__text__tfidf__analyzer': 'char', 'f...               0.591150   \n",
       "3   {'features__text__tfidf__analyzer': 'char', 'f...               0.597050   \n",
       "4   {'features__text__tfidf__analyzer': 'word', 'f...               0.559489   \n",
       "5   {'features__text__tfidf__analyzer': 'word', 'f...               0.547296   \n",
       "6   {'features__text__tfidf__analyzer': 'word', 'f...               0.603343   \n",
       "7   {'features__text__tfidf__analyzer': 'word', 'f...               0.586234   \n",
       "8   {'features__text__tfidf__analyzer': 'word', 'f...               0.554376   \n",
       "9   {'features__text__tfidf__analyzer': 'word', 'f...               0.587807   \n",
       "10  {'features__text__tfidf__analyzer': 'char', 'f...               0.573058   \n",
       "11  {'features__text__tfidf__analyzer': 'word', 'f...               0.553392   \n",
       "12  {'features__text__tfidf__analyzer': 'word', 'f...               0.569125   \n",
       "13  {'features__text__tfidf__analyzer': 'char', 'f...               0.600197   \n",
       "14  {'features__text__tfidf__analyzer': 'char', 'f...               0.520944   \n",
       "15  {'features__text__tfidf__analyzer': 'char', 'f...               0.558112   \n",
       "16  {'features__text__tfidf__analyzer': 'word', 'f...               0.585251   \n",
       "17  {'features__text__tfidf__analyzer': 'char', 'f...               0.525860   \n",
       "18  {'features__text__tfidf__analyzer': 'char', 'f...               0.514454   \n",
       "19  {'features__text__tfidf__analyzer': 'word', 'f...               0.588594   \n",
       "20  {'features__text__tfidf__analyzer': 'char', 'f...               0.564012   \n",
       "21  {'features__text__tfidf__analyzer': 'word', 'f...               0.578761   \n",
       "22  {'features__text__tfidf__analyzer': 'char', 'f...               0.601770   \n",
       "23  {'features__text__tfidf__analyzer': 'word', 'f...               0.562832   \n",
       "24  {'features__text__tfidf__analyzer': 'char', 'f...               0.566568   \n",
       "25  {'features__text__tfidf__analyzer': 'char', 'f...               0.593707   \n",
       "26  {'features__text__tfidf__analyzer': 'char', 'f...               0.562832   \n",
       "27  {'features__text__tfidf__analyzer': 'char', 'f...               0.559489   \n",
       "28  {'features__text__tfidf__analyzer': 'word', 'f...               0.590560   \n",
       "29  {'features__text__tfidf__analyzer': 'char', 'f...               0.595084   \n",
       "30  {'features__text__tfidf__analyzer': 'word', 'f...               0.554966   \n",
       "31  {'features__text__tfidf__analyzer': 'char', 'f...               0.594887   \n",
       "32  {'features__text__tfidf__analyzer': 'word', 'f...               0.565978   \n",
       "33  {'features__text__tfidf__analyzer': 'char', 'f...               0.519371   \n",
       "34  {'features__text__tfidf__analyzer': 'word', 'f...               0.570501   \n",
       "35  {'features__text__tfidf__analyzer': 'char', 'f...               0.566765   \n",
       "36  {'features__text__tfidf__analyzer': 'word', 'f...               0.569715   \n",
       "37  {'features__text__tfidf__analyzer': 'word', 'f...               0.564602   \n",
       "38  {'features__text__tfidf__analyzer': 'word', 'f...               0.540020   \n",
       "39  {'features__text__tfidf__analyzer': 'char', 'f...               0.518387   \n",
       "40  {'features__text__tfidf__analyzer': 'char', 'f...               0.593314   \n",
       "41  {'features__text__tfidf__analyzer': 'char', 'f...               0.516618   \n",
       "42  {'features__text__tfidf__analyzer': 'char', 'f...               0.519567   \n",
       "43  {'features__text__tfidf__analyzer': 'word', 'f...               0.588594   \n",
       "44  {'features__text__tfidf__analyzer': 'char', 'f...               0.582694   \n",
       "45  {'features__text__tfidf__analyzer': 'word', 'f...               0.548673   \n",
       "46  {'features__text__tfidf__analyzer': 'char', 'f...               0.588987   \n",
       "47  {'features__text__tfidf__analyzer': 'char', 'f...               0.590167   \n",
       "48  {'features__text__tfidf__analyzer': 'char', 'f...               0.592527   \n",
       "49  {'features__text__tfidf__analyzer': 'char', 'f...               0.569715   \n",
       "\n",
       "                                 cv_validation_scores  \n",
       "0   [0.6019607843137255, 0.6019607843137255, 0.589...  \n",
       "1   [0.596078431372549, 0.6098039215686275, 0.5579...  \n",
       "2   [0.6215686274509804, 0.5941176470588235, 0.565...  \n",
       "3   [0.6313725490196078, 0.6058823529411764, 0.581...  \n",
       "4   [0.5431372549019607, 0.5450980392156862, 0.559...  \n",
       "5   [0.5372549019607843, 0.5392156862745098, 0.542...  \n",
       "6   [0.6137254901960785, 0.5941176470588235, 0.612...  \n",
       "7   [0.5882352941176471, 0.5980392156862745, 0.593...  \n",
       "8   [0.5176470588235295, 0.5568627450980392, 0.573...  \n",
       "9   [0.5980392156862745, 0.5862745098039216, 0.587...  \n",
       "10  [0.5941176470588235, 0.5666666666666667, 0.544...  \n",
       "11  [0.5529411764705883, 0.5450980392156862, 0.540...  \n",
       "12  [0.5843137254901961, 0.592156862745098, 0.5481...  \n",
       "13  [0.5803921568627451, 0.6019607843137255, 0.607...  \n",
       "14  [0.5490196078431373, 0.5313725490196078, 0.508...  \n",
       "15  [0.5647058823529412, 0.5215686274509804, 0.555...  \n",
       "16  [0.592156862745098, 0.6039215686274509, 0.5933...  \n",
       "17  [0.5392156862745098, 0.5411764705882353, 0.528...  \n",
       "18  [0.5392156862745098, 0.5058823529411764, 0.528...  \n",
       "19  [0.5941176470588235, 0.5980392156862745, 0.579...  \n",
       "20  [0.5764705882352941, 0.5627450980392157, 0.573...  \n",
       "21  [0.592156862745098, 0.5823529411764706, 0.5540...  \n",
       "22  [0.6274509803921569, 0.5843137254901961, 0.587...  \n",
       "23  [0.5627450980392157, 0.5627450980392157, 0.554...  \n",
       "24  [0.596078431372549, 0.5294117647058824, 0.5461...  \n",
       "25  [0.5823529411764706, 0.615686274509804, 0.5697...  \n",
       "26  [0.5568627450980392, 0.5450980392156862, 0.565...  \n",
       "27  [0.5647058823529412, 0.5843137254901961, 0.587...  \n",
       "28  [0.6019607843137255, 0.6058823529411764, 0.597...  \n",
       "29  [0.5745098039215686, 0.592156862745098, 0.5717...  \n",
       "30  [0.5549019607843138, 0.5647058823529412, 0.542...  \n",
       "31  [0.6058823529411764, 0.596078431372549, 0.5540...  \n",
       "32  [0.5901960784313726, 0.5529411764705883, 0.565...  \n",
       "33  [0.5333333333333333, 0.5196078431372549, 0.510...  \n",
       "34  [0.5862745098039216, 0.5882352941176471, 0.542...  \n",
       "35  [0.596078431372549, 0.5725490196078431, 0.5618...  \n",
       "36  [0.5705882352941176, 0.5725490196078431, 0.579...  \n",
       "37  [0.5725490196078431, 0.5941176470588235, 0.550...  \n",
       "38  [0.5215686274509804, 0.5372549019607843, 0.550...  \n",
       "39  [0.5117647058823529, 0.4980392156862745, 0.500...  \n",
       "40  [0.5941176470588235, 0.5980392156862745, 0.581...  \n",
       "41  [0.5, 0.5549019607843138, 0.5343811394891945, ...  \n",
       "42  [0.5568627450980392, 0.492156862745098, 0.5225...  \n",
       "43  [0.5843137254901961, 0.5803921568627451, 0.603...  \n",
       "44  [0.5745098039215686, 0.596078431372549, 0.6031...  \n",
       "45  [0.5470588235294118, 0.5431372549019607, 0.546...  \n",
       "46  [0.6254901960784314, 0.5941176470588235, 0.581...  \n",
       "47  [0.596078431372549, 0.5823529411764706, 0.5717...  \n",
       "48  [0.6098039215686275, 0.596078431372549, 0.5343...  \n",
       "49  [0.5784313725490197, 0.5745098039215686, 0.546...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = pd.DataFrame(clf_behavior_RF_grid.grid_scores_)\n",
    "cv.cv_validation_scores[0]\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the one you are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_saved = joblib.load('./alcohol classifiers/behaviorBestEstimatorRF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total comps:  1272\n",
      "511 different item in whole dataset\n",
      "accuracy: 59.827044%\n",
      "F1 Score:  [0.70996785 0.50080775 0.29189189]\n",
      "RF classifier AUC:  {'current': 0.729341888493887, 'looking': 0.7399994451414426, 'reflecting': 0.6819647912380304, 'micro': 0.7646731982516515, 'macro': 0.7173064826593593}\n"
     ]
    }
   ],
   "source": [
    "# predict in testing set.\n",
    "y_behavior_RF_saved = clf_saved.predict(X_test)\n",
    "# print('length of testing set: ', len(y_alc_initial))\n",
    "computeAccuracy(y_behavior_RF_saved, y_test)\n",
    "f1_score_RF_saved = computeF1Score(y_test, y_behavior_RF_saved, average = None)\n",
    "print('F1 Score: ', f1_score_RF_saved)\n",
    "auc_score_RF_saved = computeAUCBehavior(clf_saved, X_test, y_test, plot=False, RF=True)\n",
    "# auc_score = computeAUC(clf_alc_LR_updateParams, X_train, y_train, X_test, y_test, plot=True, plotTitle=\"Alcohol ROC Curve\")\n",
    "print('RF classifier AUC: ', auc_score_RF_saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved model works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
